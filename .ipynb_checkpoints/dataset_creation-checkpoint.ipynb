{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artificial Dataset Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since it is infeasible to get real players to play the ping pong game for long amounts of time (i.e., number of matches large enough to gather sufficient data), I decided to create a synthetic dataset by pitching two computer players playing against one another. Data is stored in multiple files, collected during different runs with different ball speeds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Read and combine all the different data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Importing necessary packages \"\"\"\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['trainingSet1.json',\n",
       " 'trainingSet2.json',\n",
       " 'trainingSet3.json',\n",
       " 'trainingSet4.json',\n",
       " 'trainingSet5.json']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Creating a list of filenames that need to be opened \"\"\"\n",
    "list_of_jsons = []\n",
    "\n",
    "for i in range(5):\n",
    "    list_of_jsons.append('trainingSet' + str(i+1) + '.json')\n",
    "\n",
    "list_of_jsons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainingSet1.json\n",
      "trainingSet2.json\n",
      "trainingSet3.json\n",
      "trainingSet4.json\n",
      "trainingSet5.json\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Merge rows from all files \"\"\"\n",
    "\n",
    "df_X = pd.DataFrame()\n",
    "df_Y = pd.DataFrame()\n",
    "for json_name in list_of_jsons:\n",
    "    data = []\n",
    "    with open(json_name, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    print(json_name)\n",
    "    df_X = df_X.append(pd.DataFrame(data['xs']), ignore_index=True)\n",
    "    df_Y = df_Y.append(pd.DataFrame(data['ys']), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data X: (467925, 10)\n",
      "Data Y: (467925, 3)\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Check the sizes of X and Y \"\"\"\n",
    "print(\"Data X:\", df_X.shape)\n",
    "print(\"Data Y:\", df_Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Find and delete duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate rows: 440305\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Get a series of booleans with true for duplicate values, keeping only the first occurance of duplicates \"\"\"\n",
    "duplicates = df_X.duplicated(keep='first')\n",
    "print(\"Number of duplicate rows:\", sum(duplicates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([   443,    444,    445,    446,    447,    448,    449,    450,\n",
       "               451,    452,\n",
       "            ...\n",
       "            467915, 467916, 467917, 467918, 467919, 467920, 467921, 467922,\n",
       "            467923, 467924],\n",
       "           dtype='int64', length=440305)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Get index for values where duplicate is true \"\"\"\n",
    "duplicate_indices = duplicates[duplicates == True].index\n",
    "duplicate_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Drop duplicate rows \"\"\"\n",
    "df_X.drop(duplicate_indices, axis=0, inplace=True)\n",
    "df_Y.drop(duplicate_indices, axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Store into final_dataset.json \"\"\"\n",
    "with open('final_dataset_X.json', 'w') as file:\n",
    "    df_X_out = df_X.to_json(orient='records')\n",
    "    json.dump(fp=file, obj=df_X_out)\n",
    "\n",
    "with open('final_dataset_Y.json', 'w') as file:\n",
    "    df_Y_out = df_Y.to_json(orient='records')\n",
    "    json.dump(fp=file, obj=df_Y_out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
